{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### kNN predictor for Fisher Iris\n",
    "Data Analysis - ISAE 2020/2021 - Ahmad Berjaoui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #path handling\n",
    "import numpy as np #import numpy drives sklearn to use numpy arrays instead of python lists\n",
    "import pandas as pd #CSV and dataframe handling\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier #kNN classifier\n",
    "from sklearn.svm import LinearSVC #linear classifier\n",
    "from sklearn.neural_network import MLPClassifier #MLP classifier\n",
    "from sklearn.model_selection import train_test_split #Data set splitting functions\n",
    "from sklearn.metrics import confusion_matrix #Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './' # path to folder containing the Iris data\n",
    "dataFile = os.path.join(dataPath,'iris.data') # data file to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data import and formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalL</th>\n",
       "      <th>sepalW</th>\n",
       "      <th>petalL</th>\n",
       "      <th>petalW</th>\n",
       "      <th>FType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepalL  sepalW  petalL  petalW            FType\n",
       "9       4.9     3.1     1.5     0.1      Iris-setosa\n",
       "57      4.9     2.4     3.3     1.0  Iris-versicolor\n",
       "110     6.5     3.2     5.1     2.0   Iris-virginica\n",
       "78      6.0     2.9     4.5     1.5  Iris-versicolor\n",
       "139     6.9     3.1     5.4     2.1   Iris-virginica\n",
       "31      5.4     3.4     1.5     0.4      Iris-setosa\n",
       "126     6.2     2.8     4.8     1.8   Iris-virginica\n",
       "112     6.8     3.0     5.5     2.1   Iris-virginica\n",
       "12      4.8     3.0     1.4     0.1      Iris-setosa\n",
       "106     4.9     2.5     4.5     1.7   Iris-virginica"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we assign column names based on the description file. 'FType' stands for 'Flower Type'\n",
    "fullDF = pd.read_csv(dataFile,header=None,names=['sepalL','sepalW','petalL','petalW','FType']) \n",
    "fullDF.sample(10) # let's take a random sample from the full data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalL</th>\n",
       "      <th>sepalW</th>\n",
       "      <th>petalL</th>\n",
       "      <th>petalW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sepalL      sepalW      petalL      petalW\n",
       "count  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.057333    3.758000    1.199333\n",
       "std      0.828066    0.435866    1.765298    0.762238\n",
       "min      4.300000    2.000000    1.000000    0.100000\n",
       "25%      5.100000    2.800000    1.600000    0.300000\n",
       "50%      5.800000    3.000000    4.350000    1.300000\n",
       "75%      6.400000    3.300000    5.100000    1.800000\n",
       "max      7.900000    4.400000    6.900000    2.500000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDF.describe() # quick statistical description of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a mapping function from 'Flower type' to a class number\n",
    "def dataMap(FType):\n",
    "  \"\"\"\n",
    "  Data mapping function. Assigns a class number, given a class name\n",
    "  Args:\n",
    "    FType: (str) Flower type\n",
    "  Returns: (int) Flower class\n",
    "  \"\"\"\n",
    "\n",
    "  label = 0\n",
    "  if FType == 'Iris-versicolor':\n",
    "    label = 0\n",
    "  elif FType == 'Iris-setosa':\n",
    "    label = 1\n",
    "  elif FType == 'Iris-virginica':\n",
    "    label = 2\n",
    "  else:\n",
    "    raise(RuntimeWarning(f'Unknown flower type: {FType}, using default label 0'))\n",
    "  \n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the mapping function to the input data and create a new column called 'Y'\n",
    "fullDF['Y'] = [dataMap(item) for item in fullDF['FType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalL</th>\n",
       "      <th>sepalW</th>\n",
       "      <th>petalL</th>\n",
       "      <th>petalW</th>\n",
       "      <th>FType</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepalL  sepalW  petalL  petalW            FType  Y\n",
       "110     6.5     3.2     5.1     2.0   Iris-virginica  2\n",
       "126     6.2     2.8     4.8     1.8   Iris-virginica  2\n",
       "101     5.8     2.7     5.1     1.9   Iris-virginica  2\n",
       "77      6.7     3.0     5.0     1.7  Iris-versicolor  0\n",
       "127     6.1     3.0     4.9     1.8   Iris-virginica  2\n",
       "93      5.0     2.3     3.3     1.0  Iris-versicolor  0\n",
       "24      4.8     3.4     1.9     0.2      Iris-setosa  1\n",
       "142     5.8     2.7     5.1     1.9   Iris-virginica  2\n",
       "21      5.1     3.7     1.5     0.4      Iris-setosa  1\n",
       "2       4.7     3.2     1.3     0.2      Iris-setosa  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that mapping works on a few random samples\n",
    "fullDF.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data from classes\n",
    "dataDF = fullDF[['sepalL','sepalW','petalL','petalW']]\n",
    "classDF = fullDF['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data into training data, and test data. Same splitting should be applied to classes.\n",
    "# Here, the test data size is 10% of the full dataset\n",
    "trainData,testData,trainY,testY = train_test_split(dataDF,classDF,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme c'est la première fois que l'on l'utilise, on rapelle l'idée générale de la méthode des $k$-Nearest-Neighbors : Pour une observation $\\underline{X}$, on regarde la classe des $k$ points d'entrainement les plus proches, et on choisi la classe majoritaire. C'est un classifieur souvent performant pour les problèmes déterministes, sur lesquels on n'attends pas d'effets aléatoires.\n",
    "\n",
    "L'utilisateur doit choisir la norme utilisée pour trouver les \"plus proches voisins\", et le nombre $k$. Ici, on fait le choix classique de $k = 3$ et de la norme euclidienne. C'est souvent une norme performante pour les problèmes où toutes les features évoluent dans une espace continu.\n",
    "\n",
    "Au vu de cette description, on pourrait s'étonner de la ligne $\\textit{kNN.fit()}$ qui suit. Mais pour accélérer les appels futurs au classifieur, on construit dès maintenant un $k$D tree for the training set. Ainsi il sera très rapide pour le classifieur (maintenant muni de son arbre de recherche) de trouver les $k$ voisins d'un point quelconque. C'est le calcul de cette arbre que contient l'étape $\\textit{fit}$ (ce n'est donc pas du fitting à proporement parler).\n",
    "\n",
    "Notons que l'on aurai aussi pu optimiser la valeur de $k$, et les échelles des différentes features dans la norme euclidienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a kd Tree out of our training data and use euclidian distance as a metric.\n",
    "# This can be replaced by a custom metric\n",
    "kNN = KNeighborsClassifier(n_neighbors=3,algorithm='kd_tree',metric='minkowski',p=2,n_jobs=-1)\n",
    "kNN.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  3]\n",
      " [ 0 42  0]\n",
      " [ 2  0 43]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = kNN.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que le classifieur $k$NN ne fait pas des prédictions parfaites, même sur les points d'entrainements. On apprends ainsi 2 choses :\n",
    "\n",
    "-  D'une part, on peut être (raisonnablement) confiant que l'on aura pas d'overfitting, car on a déjà pas saturé le fitting sur les points d'entrainement. En fait, comme il n'y as pas d'hyperparamètres dans la méthode $k$NN, il n'y jamais de risque d'overfitting. Sauf si l'on fait des __weighthed__ $k$NN.\n",
    "\n",
    "-  D'autre part, on a des infos sur la géométrie de l'espace des features : il y a des _iris versicolor_ dans l'envellope convexe des _iris virginica_ , et inversement. Mais sans doute qu'un critère supplémentaire (la couleur, par exemple) aurait beaucoup plus séparé les 2 groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - kNN classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 8 0]\n",
      " [1 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = kNN.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les 15 points de test, le classificateur $k$NN ne fait qu'une erreur (93 % de précision). Certes la statistique sur 15 points est contestable, mais ce résultat reste satisfaisant !\n",
    "\n",
    "Comme dit plus haut, le classifieur $k$NN standard n'a pas d'hyperparamètre. Donc si les données d'entrainement et de test ont la même origine, ce classifieur sera toujours aussi performants sur les données de test et d'entrainement (dit autrement : il n'a pas réellement été entrainé).\n",
    "\n",
    "Enfin, on remarque à nouveau que l'erreur est entre les _iris versicolor_ et les _iris virginica_ , car ces 2 groupes se recouvrent géométriquement dans l'espace des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c5161e808>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on a que 3 classes donc la visualisation n'aide pas tant que ça. Mais pour des problèmes plus complèxes avec des centaines des classes, l'oeil humain est dépassé par la forme mathématique, et une image lui convient beaucoup mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme c'est la première fois que l'on l'utilise, on rapelle l'idée générale du classifieur linéaire. C'est un classifieur donc la force réside dans la simplicité (et donc la vitesse).\n",
    "\n",
    "C'est à nouveau un classifieur très géométrique. Si l'on avait que 2 classes, l'idée serait de trouver un hyperplan de l'espace des features qui sépare les 2 groupes. Pour chaque nouvelle observation, on regarde si elle est _en dessous_ ou _au dessus_ de l'hyperplan, et on la classifie en fonction.\n",
    "\n",
    "Ici, on a 3 classes, donc c'est légérement plus complexe : on va devoir trouver 3 hyperplans. Le premier sépare la première classe des deux autres, le seconde sépare la seconde classe, et le troisième classe. La classification est alors facile pour une observation qui est _en dessous_ d'un seul des hyperplan. Par contre, j'avoue ne pas avoir compris quoi faire pour une observation _en dessous_ de 0, ou 2, hyperplans ?\n",
    "\n",
    "Pour ce classifieur-ci, il y a un vrai entrainement : la recherche des hyperplans (ou plutôt, de vecteurs normaux aux hyperplans). Mais comme il y a peu d'hyperparamètres, le risque d'overfitting reste faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=100000.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a linear classifier out of our training data and use euclidian distance as a metric.\n",
    "# This can be replaced by a custom metric\n",
    "classifier = LinearSVC(max_iter=1e5)\n",
    "classifier.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  3]\n",
      " [ 0 42  0]\n",
      " [ 2  0 43]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = classifier.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont identiques au classifieur $k$NN. On pense que les résultats sont identiques uniquement pour ce data set particulier, mais qu'en revanche on peut généraliser l'idée que la qualité des résultats est simillaire à tout les problèmes de ce genre. \n",
    "\n",
    "On confirme ensuite que les _iris versicolor_ et les _iris virginica_ vont être durs à séparer sur des critères purements géométriques (et ces 4 seuls critères).\n",
    "\n",
    "Et comme les prédictions ne sont pas parfaites sur les points d'entrainement, on peut s'attendre à ne pas voir d'overfitting. On s'y attend aussi à partir du ratio hyperparamètres sur points d'entrainement : on avait 12 hyperparamètres pour 135 points d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Linear classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 8 0]\n",
      " [1 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = classifier.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les points de test aussi, le résultat est identique à celui du classifieur $k$NN. C'était attendu, car la qualité des prédictions était la même sur les points d'entrainement, donc en l'absence d'overfitting elle doit aussi être la même sur des points de test (sous l'hypothèse que les points de test ont la même origine que les points d'entrainement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c51d99908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - MLP classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme c'est la première fois que l'on l'utilise, on rapelle l'idée générale du classifieur MLP (Multi-Layer Perceptron). Cette fois-ci, c'est un classifieur très abstrait, sans intéprétation simple.\n",
    "\n",
    "Il s'agit d'un résaeu de neurones à 3 niveaux. Les neurones du premier niveau (_input layer_ ) s'activent ou non selon les valeurs des features de l'observation. Ensuite, les neurones du second niveau (_hidden layer_ ) s'activent ou non selon l'état d'activation des neurones du premier niveau. Enfin, les neurones du dernier niveau (_output layer_ ) s'activent ou non selon l'état d'activation du second niveau.\n",
    "\n",
    "L'entrainement consiste à optimiser les fonctions qui servent à choisir si un neurone s'active ou non, en fonction des activations du niveau précédent. Pour cela, on fait de l'inférence bayésienne : on commence par une valeur arbitraire de tous les coefficients internes aux fonctions. Puis on fait une prediction pour les points d'entrainement, que l'on compare à la correction. Cette prédiction est mauvaise, mais l'erreur nous permet de corriger les coefficients. On recommence alors le processus avec les nouveaux coefficients. <br>\n",
    "Ce processus itératif est lent, mais finit (si tout se passe bien) par converger vers la valeur optimale des coefficients, c'est à dire celle qui minimise l'erreur de prédiction moyenne sur les données d'entrainement. \n",
    "\n",
    "L'avantage de ce classifieur est sa généralité, il est performant sur une large classe de problèmes, même très complexes. En revanche, la phase d'optimisation est lente, et s'il on a mis trop de neurones dans le _hidden layer_ , il y a un fort risque d'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=1000.0, solver='lbfgs')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a linear classifier out of our training data and use euclidian distance as a metric.\n",
    "# This can be replaced by a custom metric\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='logistic', max_iter=1e3)\n",
    "mlp.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  0  0]\n",
      " [ 0 42  0]\n",
      " [ 0  0 45]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = mlp.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que les prédictions sur les points d'entrainement sont parfaites. D'un coté, cela signifie que l'on a outrepassé notre problème de géométrie entre les _iris versicolor_ et  les _iris virginica_ . \n",
    "\n",
    "Par contre, c'est inquiétant vis-a-vis du risque d'overfitting : une erreur nulle est possible pour notre petit training set. Le classifieur a arrété son entrainement sur un point d'erreur nulle, mais ce point n'est qu'une solution parmi d'autres (sans doute très nombreuses). Il faudrait plus de points d'entrainement pour savoir laquelle de ces solutions explique le mieux la réalité (par opposition à l'explication de nos données finies).\n",
    "\n",
    "On peut se réprésenter l'overfitting avec le problème d'interpolation de Lagrange : si je veux expliquer $n$ point par un polynôme, il me suffit d'un polynôme de degrès $n - 1$ (et il est unique). Et si je prends un polynôme de degrés supérieur, j'ai aussi plein de solutions mais elles seront en fort désaccord en dehors des $n$ points d'entrainement. Ainsi, je suis capable de faire une prédiction si je me place dans $\\mathbb{R}_{n}[X]$, mais pas si me place dans $\\mathbb{R}_{n+1}[X]$ : j'ai trop d'hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - MLP classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 8 0]\n",
      " [1 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = mlp.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais finalement, notre classifieur MLP atteint d'aussi bons résultats que les précédents classifieurs. Il semble qu'il n'y ai pas eu d'overfitting ici. Quoique 15 tests ne forment pas une statistique suffisante pour être formel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c51e0b488>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
