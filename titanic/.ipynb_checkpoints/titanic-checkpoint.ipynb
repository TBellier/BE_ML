{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### kNN and linear classifier predictor for titanic\n",
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #computation time analysis\n",
    "import os #path handling\n",
    "import numpy as np #import numpy drives sklearn to use numpy arrays instead of python lists\n",
    "import pandas as pd #CSV and dataframe handling\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier #kNN classifier\n",
    "from sklearn.svm import LinearSVC #linear classifier\n",
    "from sklearn.neural_network import MLPClassifier #MLP classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier #Ada classifier\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision tree classifier\n",
    "from sklearn.model_selection import train_test_split #Data set splitting functions\n",
    "from sklearn.metrics import confusion_matrix #Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './' # path to folder containing the titanic data\n",
    "dataFile = os.path.join(dataPath,'titanic.csv') # data file to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data import and formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Gustafsson, Mr. Karl Gideon</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>Wiklund, Mr. Karl Johan</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3101266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>27.0</td>\n",
       "      <td>D49</td>\n",
       "      <td>C</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>Hassab, Mr. Hammad</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.0</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>Vande Walle, Mr. Nestor Cyriel</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>Olsvigen, Mr. Thor Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Fahlstrom, Mr. Arne Jonas</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>Arnold-Franchi, Mr. Josef</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>349237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Alhomaki, Mr. Ilmari Rudolf</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin Embarked     Fare                            Name  \\\n",
       "PassengerId                                                                 \n",
       "380          19.0   NaN        S   7.7750     Gustafsson, Mr. Karl Gideon   \n",
       "383          32.0   NaN        S   7.9250              Tikkanen, Mr. Juho   \n",
       "1124         21.0   NaN        S   6.4958         Wiklund, Mr. Karl Johan   \n",
       "682          27.0   D49        C  76.7292              Hassab, Mr. Hammad   \n",
       "7            54.0   E46        S  51.8625         McCarthy, Mr. Timothy J   \n",
       "201          28.0   NaN        S   9.5000  Vande Walle, Mr. Nestor Cyriel   \n",
       "683          20.0   NaN        S   9.2250     Olsvigen, Mr. Thor Anderson   \n",
       "229          18.0   NaN        S  13.0000       Fahlstrom, Mr. Arne Jonas   \n",
       "354          25.0   NaN        S  17.8000       Arnold-Franchi, Mr. Josef   \n",
       "841          20.0   NaN        S   7.9250     Alhomaki, Mr. Ilmari Rudolf   \n",
       "\n",
       "             Parch  Pclass   Sex  SibSp  Survived             Ticket  \n",
       "PassengerId                                                           \n",
       "380              0       3  male      0         0             347069  \n",
       "383              0       3  male      0         0  STON/O 2. 3101293  \n",
       "1124             0       3  male      1         0            3101266  \n",
       "682              0       1  male      0         1           PC 17572  \n",
       "7                0       1  male      0         0              17463  \n",
       "201              0       3  male      0         0             345770  \n",
       "683              0       3  male      0         0               6563  \n",
       "229              0       2  male      0         0             236171  \n",
       "354              0       3  male      1         0             349237  \n",
       "841              0       3  male      0         0   SOTON/O2 3101287  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we assign column names based on the description file. The column names are included in the csv file.\n",
    "fullDF = pd.read_csv(dataFile, index_col='PassengerId') \n",
    "fullDF.sample(10) # let's take a random sample from the full data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a mapping function from 'Embarked' to a class number\n",
    "def get_Embarked_dummies(data):\n",
    "    \"\"\"\n",
    "    Creates dummy columns to separate the three Embark ports\n",
    "    Args:\n",
    "       data: (pandas.dataframe) embarked values\n",
    "    Returns: (pandas.dataframe) embark columns\n",
    "    \"\"\"\n",
    "    data = data['Embarked']\n",
    "    columns = pd.get_dummies(data)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a mapping function from 'Pclass' to a class number\n",
    "def get_Pclass_dummies(data):\n",
    "    \"\"\"\n",
    "    Creates dummy columns to separate the three classes\n",
    "    Args:\n",
    "       data: (pandas.dataframe) classes values\n",
    "    Returns: (pandas.dataframe) classes columns\n",
    "    \"\"\"\n",
    "    data = data['Pclass']\n",
    "    new_columns = pd.get_dummies(data)\n",
    "    new_columns = new_columns.rename(columns={1: 'class1', 2: 'class2', 3: 'class3'})\n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a mapping function from 'Sex' to a class number\n",
    "def sexMap(Sex):\n",
    "  \"\"\"\n",
    "  Sex mapping function. Assigns a sex class number, given a sex name\n",
    "  Args:\n",
    "    Sex: (str) sex\n",
    "  Returns: (int) sex class\n",
    "  \"\"\"\n",
    "\n",
    "  label = np.nan\n",
    "  if Sex == 'female':\n",
    "    label = 0\n",
    "  elif Sex == 'male':\n",
    "    label = 1\n",
    "  else:\n",
    "    raise(RuntimeWarning(f'Unknown sex type: {Sex}, using default label NaN'))\n",
    "  \n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the mapping functions to the input data\n",
    "fullDF = fullDF.join(get_Embarked_dummies(fullDF))\n",
    "fullDF = fullDF.join(get_Pclass_dummies(fullDF))\n",
    "fullDF['Sex'] = fullDF['Sex'].map(sexMap)\n",
    "usefulDF = fullDF[['Age', 'S', 'Q', 'C', 'Fare', 'Parch', 'class1', 'class2', 'class3', 'Sex', 'SibSp', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove NaNs (to change)\n",
    "usefulDF = usefulDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>C</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  S  Q  C     Fare  Parch  class1  class2  class3  Sex  \\\n",
       "PassengerId                                                               \n",
       "138          37.0  1  0  0  53.1000      0       1       0       0    1   \n",
       "363          45.0  0  0  1  14.4542      1       0       0       1    0   \n",
       "489          30.0  1  0  0   8.0500      0       0       0       1    1   \n",
       "52           21.0  1  0  0   7.8000      0       0       0       1    1   \n",
       "226          22.0  1  0  0   9.3500      0       0       0       1    1   \n",
       "646          48.0  0  0  1  76.7292      0       1       0       0    1   \n",
       "637          32.0  1  0  0   7.9250      0       0       0       1    1   \n",
       "763          20.0  0  0  1   7.2292      0       0       0       1    1   \n",
       "949          25.0  1  0  0   7.6500      0       0       0       1    1   \n",
       "691          31.0  1  0  0  57.0000      0       1       0       0    1   \n",
       "\n",
       "             SibSp  Survived  \n",
       "PassengerId                   \n",
       "138              1         0  \n",
       "363              0         0  \n",
       "489              0         0  \n",
       "52               0         0  \n",
       "226              0         0  \n",
       "646              1         1  \n",
       "637              0         0  \n",
       "763              0         1  \n",
       "949              0         0  \n",
       "691              1         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that mapping works on a few random samples\n",
    "usefulDF.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data from classes\n",
    "dataDF = usefulDF[['Age', 'S', 'Q', 'C', 'Fare', 'Parch', 'class1', 'class2', 'class3', 'Sex', 'SibSp']]\n",
    "classDF = usefulDF['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data into training data, and test data. Same splitting should be applied to classes.\n",
    "# Here, the test data size is 10% of the full dataset\n",
    "trainData,testData,trainY,testY = train_test_split(dataDF,classDF,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà expliqué l'idée de cet algorithme dans le notebook sur les Iris. Notons simplement que l'on s'attends à de moins bon résultats cette fois-ci, car il y a une part d'_aléatoire_ . C'est à dire que deux fleurs de même taille, de même nombre de pétales, de même couleur, etc. sont toujours de la même espèce. Alors parmi deux passagers de même age, de même sexe, et dans la même classe, l'un peut survivre et pas l'autre.\n",
    "\n",
    "On s'attends en particulier à de pauvres résultats pour le classifieur $k$NN, qui n'est généralement pas très performant sur les problèmes avec de l'aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a kd Tree out of our training data and use euclidian distance as a metric.\n",
    "# This can be replaced by a custom metric\n",
    "start_time = time.time()\n",
    "kNN = KNeighborsClassifier(n_neighbors=3,algorithm='kd_tree',metric='minkowski',p=2,n_jobs=-1)\n",
    "kNN.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[511  61]\n",
      " [110 258]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = kNN.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et comme prévu, le classifieur $k$NN a, pour ce problème-ci, un taux d'errereur de 18% sur les points d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - kNN classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 11]\n",
      " [27 22]]\n",
      "0.638095238095238\n",
      "--- 0.2949032783508301 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = kNN.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)\n",
    "accuracy = float(np.sum([testCM[i][i] for i in range(len(testCM))]))/float(len(testY))\n",
    "print(accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux d'erreur monte même à 37% pour les points d'entrainement. Mais on suspecte que c'est un effet non significatif, car le classifieur $k$NN standard n'est pas supposé être moins bon sur les points d'entrainement que sur les points de test : il n'as subit aucun entrainement.\n",
    "\n",
    "Le taux d'erreur réel (pour ce problème çi) est donc sans doute quelque part entre 20% et 40%. On pourrait en obtenir une estimation plus fine avec une méthode de _leave-one-out_ : on fait $n$ groupes de points, on entraine le classifieur sur $n-1$ groupes et on le test sur le dernier groupe. On fait ça $n$ fois en laissant un groupe différent de coté à chaque fois, puis on fait le moyenne des taux d'erreur sur les $n$ tests. On a ainsi des statistiques bien meilleures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a4c826c48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà expliqué l'idée de cet algorithme dans le notebook sur les Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=1000000.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a linear classifier out of our training data and use euclidian distance as a metric.\n",
    "# This can be replaced by a custom metric\n",
    "start_time = time.time()\n",
    "classifier = LinearSVC(max_iter=1e6)\n",
    "classifier.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = classifier.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Linear classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  7]\n",
      " [16 33]]\n",
      "[[515  57]\n",
      " [ 77 291]]\n",
      "0.780952380952381\n",
      "--- 19.203729152679443 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = classifier.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)\n",
    "print(trainCM)\n",
    "accuracy = float(np.sum([testCM[i][i] for i in range(len(testCM))]))/float(len(testY))\n",
    "print(accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait que les résultats du classifieur linéaire soit meilleurs que ceux du classifieur $k$NN. Ce n'est pas absurde : le classifieur linéaire a été entrainé pour ce problème précis, dons spécialisé pour cette tâche. Ce n'est pas le cas du classifieur $k$NN. Mais cet argument est vraiment très heuristique, il est facile de construire un jeu de données où le classifieur $k$NN est bien meillleur que le classifieur linéaire. <br>\n",
    "Par exemple, on prend une classe dans un disque, et une seconde classe qui l'entoure. La séparation des classes par un hyperplan est impossible, alors que l'on a bien 2 groupes géométriques.\n",
    "\n",
    "Enfin, le classifieur linéaire est bien plus lent, et c'est généralement le cas : il faut un entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a4d0cbdc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - MLP classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà expliqué l'idée de cet algorithme dans le notebook sur les Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a MLP classifier.\n",
    "start_time = time.time()\n",
    "mlp = MLPClassifier(solver='adam', activation='logistic', max_iter=10000)\n",
    "mlp.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[522  50]\n",
      " [ 75 293]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = mlp.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - MLP classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  5]\n",
      " [16 33]]\n",
      "0.8\n",
      "--- 0.7740631103515625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = mlp.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)\n",
    "accuracy = float(np.sum([testCM[i][i] for i in range(len(testCM))]))/float(len(testY))\n",
    "print(accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le classifieur MLP atteint des performances simillaires au classifieur linéaire, mais dans des temps de calcul plus court.\n",
    "\n",
    "Nous ne sommes pas surpris : le MLP est adapté aux problèmes avec une part d'aléatoire, car il est construit dés l'origine dans un cadre Bayésien. Par contre, nous n'avons pas complétement compris pourquoi MLP est plus rapide (converge en moins d'itérations) que l'optimisateur linéaire, alors qu'il a plus d'hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a4d7aa088>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Decision tree classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme c'est la première fois que l'on l'utilise, on rapelle l'idée générale du classifieur par arbre de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a decision tree classifier.\n",
    "start_time = time.time()\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[572   0]\n",
      " [ 12 356]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = dtc.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Decision tree classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 11]\n",
      " [13 36]]\n",
      "0.7714285714285715\n",
      "--- 0.03444337844848633 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = dtc.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)\n",
    "accuracy = float(np.sum([testCM[i][i] for i in range(len(testCM))]))/float(len(testY))\n",
    "print(accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a4d7fd088>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAF0UlEQVR4nO3bv6vd9R3H8dc7N0l/UAqtZqmG6iBClnYI/gelsYurWStk8g/wH3HJENyUjg5Chi5CkdZMRVtsg1AMDqa6FWpq+HRxCBq458Zz8o15PR7b98vhe1/wvU++53DPnbVWgMfbqa0HAIcndCggdCggdCggdCggdCgg9BOYmUsz89HM3JyZ17bew+5m5trMfDYzH2y9ZQtC39HMHCV5PcmLSS4kuTwzF7ZdxQm8keTS1iO2IvTdvZDk5lrr47XWnSRvJXlp403saK31bpIvtt6xFaHv7qkkn9xzfOvrc/DIE/ru5j7nfH+Y7wWh7+5WkvP3HD+d5NONtsCJCH137yd5bmaenZmzSV5O8vbGm2AnQt/RWuurJK8muZ7k70n+sNb6cNtV7Gpm3kzyXpLnZ+bWzLyy9aaHafybKjz+PNGhgNChgNChgNChgNChgNBPaGaubL2BB9d6/4R+cpW/KI+RyvsndChwkC/MPPnzo/XM+TN7v+6j4Pbnd3PuiaOtZxzUP/76460nHMz/8mXO5AdbzziY/+Y/ubO+/NY/YJ0+xA975vyZ/OX6+eNfyCPpt7/49dYTeEB/Xn+873lv3aGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KGA0KHATqHPzKWZ+Whmbs7Ma4ceBezXsaHPzFGS15O8mORCksszc+HQw4D92eWJ/kKSm2utj9dad5K8leSlw84C9mmX0J9K8sk9x7e+Pgd8T+wS+tzn3PrWi2auzMyNmblx+/O7330ZsDe7hH4ryfl7jp9O8uk3X7TWurrWurjWunjuiaN97QP2YJfQ30/y3Mw8OzNnk7yc5O3DzgL26fRxL1hrfTUzrya5nuQoybW11ocHXwbszbGhJ8la650k7xx4C3AgvhkHBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBYQOBU4f4qL//NtP87tf/eYQl+Yh+Nmf7m49gQd0+vdH9z3viQ4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4FhA4Fjg19Zq7NzGcz88HDGATs3y5P9DeSXDrwDuCAjg19rfVuki8ewhbgQHxGhwKn93WhmbmS5EqS/PDUT/Z1WWAP9vZEX2tdXWtdXGtdPHvqR/u6LLAH3rpDgV3+vPZmkveSPD8zt2bmlcPPAvbp2M/oa63LD2MIcDjeukMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUMBoUOBWWvt/6Izt5P8a+8XfjQ8meTfW4/ggT3u9++Xa61z3zx5kNAfZzNzY611cesdPJjW++etOxQQOhQQ+sld3XoA30nl/fMZHQp4okMBoUMBoUMBoUMBoUOB/wPP1rIbHZ/nVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - AdaBoost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a AdaBoost classifier.\n",
    "start_time = time.time()\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\n",
    "ada.fit(trainData,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[522  50]\n",
      " [ 69 299]]\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the training data\n",
    "trainPredictions = ada.predict(trainData)\n",
    "trainCM = confusion_matrix(y_pred=trainPredictions,y_true=trainY)\n",
    "print(trainCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - AdaBoost classifier performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  5]\n",
      " [13 36]]\n",
      "0.8285714285714286\n",
      "--- 0.11165642738342285 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier's performance on the test data\n",
    "predictions = ada.predict(testData)\n",
    "testCM = confusion_matrix(y_pred=predictions,y_true=testY)\n",
    "print(testCM)\n",
    "accuracy = float(np.sum([testCM[i][i] for i in range(len(testCM))]))/float(len(testY))\n",
    "print(accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a4d850e08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can also plot the confusion matrix\n",
    "plt.matshow(testCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
